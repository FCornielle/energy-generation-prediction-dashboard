{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 'parque solar girasol' - shape: (31012, 27)\n",
      "Saved data for 'parque solar girasol' to ..\\data\\interim\\meteo_data_with_generation\\parque_solar_girasol.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_generation_data(gen_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load generation data from a Parquet file.\n",
    "    \"\"\"\n",
    "    df_gen = pd.read_parquet(gen_path)\n",
    "    df_gen[\"timestamp\"] = pd.to_datetime(df_gen[\"timestamp\"], utc=True)\n",
    "    df_gen = df_gen.set_index(\"timestamp\")\n",
    "    return df_gen\n",
    "\n",
    "def load_lookup_data(lookup_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load lookup data from a CSV file containing plant info.\n",
    "    \"\"\"\n",
    "    df_lookup = pd.read_csv(lookup_path)\n",
    "    expected_cols = [\"CENTRAL\", \"FirstAppearance\"]\n",
    "    for col in expected_cols:\n",
    "        if col not in df_lookup.columns:\n",
    "            raise KeyError(\n",
    "                f\"Expected column '{col}' not found in lookup file. \"\n",
    "                f\"Found columns: {df_lookup.columns.tolist()}\"\n",
    "            )\n",
    "    df_lookup[\"firstappearance\"] = pd.to_datetime(df_lookup[\"FirstAppearance\"], utc=True)\n",
    "    df_lookup[\"central\"] = df_lookup[\"CENTRAL\"].str.lower()\n",
    "    return df_lookup\n",
    "\n",
    "def load_and_process_meteo_file(meteo_file: Path, shift_hours: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load meteorological data from a Parquet file, optionally shifting the timestamps\n",
    "    by 'shift_hours' to correct any offset.\n",
    "\n",
    "    Args:\n",
    "        meteo_file (Path): Path to a meteorological Parquet file.\n",
    "        shift_hours (int): Number of hours to shift the timestamps. \n",
    "                           Positive shifts the data forward, negative backward.\n",
    "    \"\"\"\n",
    "    df_meteo = pd.read_parquet(meteo_file)\n",
    "\n",
    "    # Identify the column containing datetime\n",
    "    if \"date\" in df_meteo.columns:\n",
    "        date_col = \"date\"\n",
    "    elif \"timestamp\" in df_meteo.columns:\n",
    "        date_col = \"timestamp\"\n",
    "    else:\n",
    "        raise KeyError(f\"Neither 'date' nor 'timestamp' column found in file: {meteo_file}\")\n",
    "\n",
    "    # Convert to UTC datetime\n",
    "    df_meteo[date_col] = pd.to_datetime(df_meteo[date_col], utc=True)\n",
    "\n",
    "    # Shift by 'shift_hours' if needed\n",
    "    if shift_hours != 0:\n",
    "        df_meteo[date_col] = df_meteo[date_col] + pd.Timedelta(hours=shift_hours)\n",
    "\n",
    "    # Rename to 'date' and set as index\n",
    "    df_meteo = df_meteo.rename(columns={date_col: \"date\"})\n",
    "    df_meteo = df_meteo.set_index(\"date\")\n",
    "    return df_meteo\n",
    "\n",
    "def merge_generation_and_meteo(df_gen: pd.DataFrame, df_meteo: pd.DataFrame, plant_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge generation and meteorological data based on their date.\n",
    "    \"\"\"\n",
    "    if plant_name not in df_gen.columns:\n",
    "        raise KeyError(f\"Generation column '{plant_name}' not found in generation data.\")\n",
    "    df_gen_temp = df_gen[[plant_name]].reset_index().rename(columns={\"timestamp\": \"date\", plant_name: \"generation\"})\n",
    "    df_meteo_temp = df_meteo.reset_index()\n",
    "    df_model = pd.merge(df_gen_temp, df_meteo_temp, on=\"date\", how=\"inner\")\n",
    "    return df_model\n",
    "\n",
    "def update_first_appearance_date(df_model: pd.DataFrame, plant_name: str, df_lookup: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Update the first appearance date in the merged DataFrame using lookup data.\n",
    "    \"\"\"\n",
    "    if plant_name in df_lookup[\"central\"].values:\n",
    "        lookup_date = df_lookup.loc[df_lookup[\"central\"] == plant_name, \"firstappearance\"].iloc[0]\n",
    "        earliest_date = df_model[\"date\"].min()\n",
    "        df_model.loc[df_model[\"date\"] == earliest_date, \"date\"] = lookup_date\n",
    "    else:\n",
    "        print(f\"Warning: Plant '{plant_name}' not found in lookup file.\")\n",
    "    return df_model\n",
    "\n",
    "def process_all_meteo_files(gen_path: Path, meteo_dir: Path, lookup_path: Path, shift_hours: int = 4) -> dict:\n",
    "    \"\"\"\n",
    "    Process all meteorological files by merging generation data and updating the first appearance date.\n",
    "    \"\"\"\n",
    "    df_gen = load_generation_data(gen_path)\n",
    "    df_lookup = load_lookup_data(lookup_path)\n",
    "    merged_dfs = {}\n",
    "\n",
    "    for meteo_file in meteo_dir.glob(\"*.parquet\"):\n",
    "        plant_name = meteo_file.stem\n",
    "        plant_name_formatted = plant_name.replace(\"_\", \" \").lower()\n",
    "\n",
    "        try:\n",
    "            # Load meteo with a time shift if needed\n",
    "            df_meteo = load_and_process_meteo_file(meteo_file, shift_hours=shift_hours)\n",
    "\n",
    "            # Merge generation and meteo\n",
    "            df_model = merge_generation_and_meteo(df_gen, df_meteo, plant_name_formatted)\n",
    "\n",
    "            # Update earliest date from lookup\n",
    "            df_model = update_first_appearance_date(df_model, plant_name_formatted, df_lookup)\n",
    "            merged_dfs[plant_name_formatted] = df_model\n",
    "\n",
    "            print(f\"Processed '{plant_name_formatted}' - shape: {df_model.shape}\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Skipping file '{meteo_file.name}': {e}\")\n",
    "\n",
    "    return merged_dfs\n",
    "\n",
    "# -------------------------------------------\n",
    "# MAIN EXECUTION\n",
    "# -------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    GEN_PATH = Path(\"../data/interim/post_despacho_transformed.parquet\")\n",
    "    METEO_DIR = Path(\"../data/raw/open_meteo_data/\")\n",
    "    LOOKUP_PATH = Path(\"../data/lookup/central_info.csv\")\n",
    "\n",
    "    # Adjust shift_hours as needed (+4, -4, etc.)\n",
    "    merged_data = process_all_meteo_files(GEN_PATH, METEO_DIR, LOOKUP_PATH, shift_hours=-4)\n",
    "\n",
    "    # Save each merged DataFrame\n",
    "    output_dir = Path(\"../data/interim/meteo_data_with_generation\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for plant_name, df in merged_data.items():\n",
    "        file_name = f\"{plant_name.replace(' ', '_')}.parquet\"\n",
    "        output_path = output_dir / file_name\n",
    "        df.to_parquet(output_path, index=False)\n",
    "        print(f\"Saved data for '{plant_name}' to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
