{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and Merge Generation Data from .parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged 4461 DataFrames.\n",
      "The resulting DataFrame has 476594 rows and 30 columns.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "# Folder containing the .parquet files\n",
    "folder_path = r\"..\\data\\raw\"\n",
    "\n",
    "# Find all .parquet files in the folder\n",
    "parquet_files = glob.glob(os.path.join(folder_path, \"*.parquet\"))\n",
    "\n",
    "if not parquet_files:\n",
    "    print(\"No Parquet files were found in the specified folder.\")\n",
    "else:\n",
    "    # Load each Parquet file and add it to a list\n",
    "    df_list = []\n",
    "    for file in parquet_files:\n",
    "        #print(f\"Importing {file}...\")\n",
    "        df_temp = pd.read_parquet(file)\n",
    "        df_list.append(df_temp)\n",
    "\n",
    "    # Concatenate all DataFrames into a single one\n",
    "    df_merged = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"\\nMerged {len(df_list)} DataFrames.\")\n",
    "    print(f\"The resulting DataFrame has {df_merged.shape[0]} rows and {df_merged.shape[1]} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normilize_string and Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Functions ---\n",
    "\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_string(s):\n",
    "    \"\"\"\n",
    "    Converts a string to lowercase and removes accents.\n",
    "    \n",
    "    Parameters:\n",
    "        s (str): The input string.\n",
    "    \n",
    "    Returns:\n",
    "        str: The normalized string.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))\n",
    "    return s\n",
    "\n",
    "def normalize_central_column(df, column=\"CENTRAL\"):\n",
    "    \"\"\"\n",
    "    Normalizes the values in the specified column by converting to lowercase and removing accents.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the column.\n",
    "        column (str): Column name to normalize (default \"CENTRAL\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame.\n",
    "    \"\"\"\n",
    "    df[column] = df[column].astype(str).apply(normalize_string)\n",
    "    return df\n",
    "\n",
    "def format_fecha_column(df, column=\"FECHA\"):\n",
    "    \"\"\"\n",
    "    Converts the specified date column to datetime using '%Y-%m-%dT%H:%M:%S'.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the date column.\n",
    "        column (str): Column name to format (default \"FECHA\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame.\n",
    "    \"\"\"\n",
    "    df[column] = pd.to_datetime(df[column], format='%Y-%m-%dT%H:%M:%S', errors='coerce')\n",
    "    return df\n",
    "\n",
    "def remove_unwanted_units(df, unit_col=\"CENTRAL\"):\n",
    "    \"\"\"\n",
    "    Removes rows from the DataFrame where the unit (in unit_col) is in the exclude list.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with the unit column.\n",
    "        unit_col (str): Name of the unit column (default \"CENTRAL\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with unwanted units removed.\n",
    "    \"\"\"\n",
    "    exclude_units = [\n",
    "        \"arroyo barril\",\n",
    "        \"cayman\",\n",
    "        \"dajabon\",\n",
    "        \"los mina 1\",\n",
    "        \"los mina 2\",\n",
    "        \"haina 3\",\n",
    "        \"puerto plata 1\",\n",
    "        \"puerto plata 2\",\n",
    "        \"santo domingo 5\",\n",
    "        \"santo domingo 8\",\n",
    "        \"timbeque 1\",\n",
    "        \"timbeque 2\"\n",
    "    ]\n",
    "    df = df[~df[unit_col].isin(exclude_units)]\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_next_available(df, date_col='FECHA', central_col='CENTRAL', max_offset=14):\n",
    "    \"\"\"\n",
    "    Fills missing dates in the DataFrame by finding records from a subsequent date that \n",
    "    has the same weekday as the missing date. For each missing date, the function checks\n",
    "    offsets starting at 7 days up to max_offset days. If a record is found, it is duplicated \n",
    "    and its date is set to the missing date.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with at least the date_col and central_col.\n",
    "        date_col (str): Name of the date column (assumed to be datetime).\n",
    "        central_col (str): Name of the plant column.\n",
    "        max_offset (int): Maximum number of days offset to check (default is 14).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing dates filled.\n",
    "    \"\"\"\n",
    "    df[date_col] = pd.to_datetime(df[date_col]).dt.normalize()\n",
    "    all_dates = pd.date_range(start=df[date_col].min(), end=df[date_col].max())\n",
    "    present_dates = pd.to_datetime(df[date_col].unique())\n",
    "    missing_dates = all_dates.difference(present_dates)\n",
    "    \n",
    "    fill_rows = []\n",
    "    \n",
    "    for missing_date in missing_dates:\n",
    "        filled = False\n",
    "        for offset in range(7, max_offset + 1):\n",
    "            candidate_date = missing_date + pd.Timedelta(days=offset)\n",
    "            if candidate_date.weekday() != missing_date.weekday():\n",
    "                continue\n",
    "            df_candidate = df[df[date_col] == candidate_date]\n",
    "            if not df_candidate.empty:\n",
    "                for _, row in df_candidate.iterrows():\n",
    "                    new_row = row.copy()\n",
    "                    new_row[date_col] = missing_date\n",
    "                    fill_rows.append(new_row)\n",
    "                filled = True\n",
    "                break\n",
    "        if not filled:\n",
    "            print(f\"No matching record found to fill missing date {missing_date.date()}\")\n",
    "    \n",
    "    if fill_rows:\n",
    "        df_filled = pd.concat([df, pd.DataFrame(fill_rows)], ignore_index=True)\n",
    "    else:\n",
    "        df_filled = df.copy()\n",
    "    \n",
    "    df_filled = df_filled.sort_values(by=[central_col, date_col]).reset_index(drop=True)\n",
    "    return df_filled\n",
    "def standardize_central_names(df, column=\"CENTRAL\"):\n",
    "    \"\"\"\n",
    "    Standardizes central names by applying a mapping. This function assumes that the values \n",
    "    in the specified column are already in lowercase.\n",
    "    \n",
    "    Mappings applied:\n",
    "      - \"central hidroelectrica hatillo 2\" -> \"hatillo 2\"\n",
    "      - \"parque fotovoltaico bayahonda (bayasol)\" -> \"parque fotovoltaico bayasol\"\n",
    "      - \"parque fotovoltaico montecristi solar1\" -> \"parque fotovoltaico montecristi solar 1\"\n",
    "      - \"parque eolico los guzmancito 2\" -> \"parque eolico los guzmancitos 2\"\n",
    "      - \"hatillo\" -> \"hatillo 1\"\n",
    "      - \"juancho los cocos 1\" -> \"los cocos 1\"\n",
    "      - \"aes andres xxxxxx\" -> \"aes andres\"\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the central names.\n",
    "        column (str): Name of the column to standardize (default \"CENTRAL\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with standardized central names.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"central hidroelectrica hatillo 2\": \"hatillo 2\",\n",
    "        \"parque fotovoltaico bayahonda (bayasol)\": \"parque fotovoltaico bayasol\",\n",
    "        \"parque fotovoltaico montecristi solar1\": \"parque fotovoltaico montecristi solar 1\",\n",
    "        \"parque eolico los guzmancito 2\": \"parque eolico los guzmancitos 2\",\n",
    "        \"hatillo\": \"hatillo 1\",\n",
    "        \"juancho los cocos 1\": \"los cocos 1\",\n",
    "        \"aes andres xxxxxx\": \"aes andres\"\n",
    "    }\n",
    "    \n",
    "    df[column] = df[column].replace(mapping)\n",
    "    return df\n",
    "def remove_daily_duplicates_by_max_hours(df, date_col=\"FECHA\", unit_col=\"CENTRAL\"):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows for the same unit (central) and date by keeping only the row \n",
    "    with the highest sum of hour columns (H1 to H24).\n",
    "    \n",
    "    Assumes the date column is already normalized (i.e., time set to midnight).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing at least the columns specified in date_col, \n",
    "                           unit_col, and hour columns (H1...H24).\n",
    "        date_col (str): Name of the date column (default \"FECHA\").\n",
    "        unit_col (str): Name of the central column (default \"CENTRAL\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed, keeping only the row with the maximum \n",
    "                      hour sum for each combination of unit and date.\n",
    "    \"\"\"\n",
    "    # Identify hour columns (H1 to H24) present in the DataFrame\n",
    "    hour_cols = [f\"H{i}\" for i in range(1, 25) if f\"H{i}\" in df.columns]\n",
    "    if not hour_cols:\n",
    "        print(\"No hour columns found in the DataFrame.\")\n",
    "        return df\n",
    "    \n",
    "    # Calculate the sum of hour columns for each row and add it as a temporary column\n",
    "    df[\"hour_sum\"] = df[hour_cols].sum(axis=1, skipna=True)\n",
    "    \n",
    "    # Group by date and unit, and select the index of the row with the maximum hour_sum for each group\n",
    "    idx = df.groupby([date_col, unit_col])[\"hour_sum\"].idxmax()\n",
    "    \n",
    "    # Retrieve those rows and remove the temporary hour_sum column\n",
    "    df_unique = df.loc[idx].copy()\n",
    "    df_unique.drop(columns=[\"hour_sum\"], inplace=True)\n",
    "    \n",
    "    return df_unique\n",
    "\n",
    "def aggregate_unit_groups(df, group_mapping, date_col=\"FECHA\", unit_col=\"CENTRAL\"):\n",
    "    \"\"\"\n",
    "    Aggregates rows for unit groups based on a mapping.\n",
    "    \n",
    "    For each group defined in group_mapping (where the key is the unified unit name and the value\n",
    "    is a list of variants), the function:\n",
    "      1. Filters rows where unit_col is in the variants.\n",
    "      2. Groups these rows by the date (date_col) and sums the hourly columns (H1 to H24).\n",
    "      3. Creates new rows with the unified unit name (the key).\n",
    "      4. Removes the original rows for these variants from the DataFrame.\n",
    "      5. Appends the aggregated rows back to the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): DataFrame containing at least the date_col, unit_col, and hourly columns (H1 ... H24).\n",
    "      group_mapping (dict): Dictionary where keys are the unified unit names and values are lists of variants.\n",
    "      date_col (str): Name of the date column (default \"FECHA\").\n",
    "      unit_col (str): Name of the unit column (default \"CENTRAL\").\n",
    "    \n",
    "    Returns:\n",
    "      pd.DataFrame: DataFrame with aggregated rows for each specified group.\n",
    "    \"\"\"\n",
    "    # Identify hourly columns (H1 to H24) that exist in the DataFrame\n",
    "    hour_cols = [f\"H{i}\" for i in range(1, 25) if f\"H{i}\" in df.columns]\n",
    "    if not hour_cols:\n",
    "        print(\"No hourly columns found in the DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    # Normalize the date column (set time to midnight)\n",
    "    df[date_col] = pd.to_datetime(df[date_col]).dt.normalize()\n",
    "    \n",
    "    aggregated_rows = []\n",
    "    \n",
    "    # Loop over each group in the mapping\n",
    "    for unified_unit, variants in group_mapping.items():\n",
    "        # Filter rows where unit is in the variants list\n",
    "        mask = df[unit_col].isin(variants)\n",
    "        df_group = df[mask].copy()\n",
    "        if df_group.empty:\n",
    "            continue\n",
    "        # Group by date and sum the hourly columns\n",
    "        df_agg = df_group.groupby(date_col, as_index=False)[hour_cols].sum()\n",
    "        # Set the unit column to the unified unit for all aggregated rows\n",
    "        df_agg[unit_col] = unified_unit\n",
    "        \n",
    "        aggregated_rows.append(df_agg)\n",
    "    \n",
    "    # If any aggregated rows were created, combine them\n",
    "    if aggregated_rows:\n",
    "        df_aggregated = pd.concat(aggregated_rows, ignore_index=True)\n",
    "    else:\n",
    "        df_aggregated = pd.DataFrame(columns=[date_col, unit_col] + hour_cols)\n",
    "    \n",
    "    # Remove original rows that belong to any of the variants in the mapping\n",
    "    all_variants = [variant for variants in group_mapping.values() for variant in variants]\n",
    "    df_remaining = df[~df[unit_col].isin(all_variants)]\n",
    "    \n",
    "    # Combine the remaining rows with the aggregated rows\n",
    "    df_result = pd.concat([df_remaining, df_aggregated], ignore_index=True)\n",
    "    \n",
    "    # Sort by unit and date for clarity\n",
    "    df_result = df_result.sort_values(by=[unit_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "def aggregate_los_mina(df, date_col=\"FECHA\", unit_col=\"CENTRAL\"):\n",
    "    \"\"\"\n",
    "    Aggregates rows for 'los mina' by processing two groups:\n",
    "      - Group 1: Sum hourly values from rows with unit in [\"los mina 5\", \"los mina 6\", \"los mina 7\"].\n",
    "      - Group 2: For rows with unit in [\"parque energetico los mina cc parcial\", \"parque energetico los mina cc total\"],\n",
    "                 select the row with the maximum hour sum (H1 to H24) for each day.\n",
    "    \n",
    "    For each day with data in either group, a new aggregated row with unit \"los mina\" is created,\n",
    "    with hourly values equal to the sum of Group 1 and Group 2 values.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): DataFrame containing at least the date_col, unit_col, and hourly columns (H1 ... H24).\n",
    "      date_col (str): Name of the date column (assumed to be datetime or will be normalized).\n",
    "      unit_col (str): Name of the unit/central column.\n",
    "      \n",
    "    Returns:\n",
    "      pd.DataFrame: DataFrame with the original rows for these groups removed and replaced with aggregated rows.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is datetime and normalized (time set to midnight)\n",
    "    df[date_col] = pd.to_datetime(df[date_col]).dt.normalize()\n",
    "    \n",
    "    # Determine hourly columns (H1 to H24) available in df\n",
    "    hour_cols = [f\"H{i}\" for i in range(1, 25) if f\"H{i}\" in df.columns]\n",
    "    if not hour_cols:\n",
    "        print(\"No hourly columns found.\")\n",
    "        return df\n",
    "    \n",
    "    # Define the variant groups\n",
    "    group1_variants = [\"los mina 5\", \"los mina 6\", \"los mina 7\"]\n",
    "    group2_variants = [\"parque energetico los mina cc parcial\", \"parque energetico los mina cc total\"]\n",
    "    \n",
    "    # Filter rows for each group\n",
    "    df_group1 = df[df[unit_col].isin(group1_variants)].copy()\n",
    "    df_group2 = df[df[unit_col].isin(group2_variants)].copy()\n",
    "    \n",
    "    # Determine all unique dates where either group has data\n",
    "    dates = pd.to_datetime(pd.concat([df_group1[date_col], df_group2[date_col]]).unique())\n",
    "    \n",
    "    aggregated_rows = []\n",
    "    \n",
    "    for d in dates:\n",
    "        # Initialize aggregated hourly values for the day as zeros\n",
    "        agg_values = {col: 0 for col in hour_cols}\n",
    "        \n",
    "        # Group 1 aggregation: Sum rows for the date d if present\n",
    "        df1_d = df_group1[df_group1[date_col] == d]\n",
    "        if not df1_d.empty:\n",
    "            sum_group1 = df1_d[hour_cols].sum()\n",
    "            for col in hour_cols:\n",
    "                agg_values[col] += sum_group1[col]\n",
    "        \n",
    "        # Group 2 aggregation: For the date d, select the row with maximum hour sum if present\n",
    "        df2_d = df_group2[df_group2[date_col] == d].copy()  # <-- Make an explicit copy here\n",
    "        if not df2_d.empty:\n",
    "            df2_d[\"hour_sum\"] = df2_d[hour_cols].sum(axis=1, skipna=True)\n",
    "            idx = df2_d[\"hour_sum\"].idxmax()\n",
    "            max_row = df2_d.loc[idx]\n",
    "            for col in hour_cols:\n",
    "                agg_values[col] += max_row[col]\n",
    "        \n",
    "        # Create the aggregated row if there was data in either group for the day\n",
    "        if not (df1_d.empty and df_group2.empty):\n",
    "            new_row = {date_col: d, unit_col: \"los mina\"}\n",
    "            for col in hour_cols:\n",
    "                new_row[col] = agg_values[col]\n",
    "            aggregated_rows.append(new_row)\n",
    "    \n",
    "    # Create a DataFrame from aggregated rows\n",
    "    if aggregated_rows:\n",
    "        df_aggregated = pd.DataFrame(aggregated_rows)\n",
    "    else:\n",
    "        df_aggregated = pd.DataFrame(columns=[date_col, unit_col] + hour_cols)\n",
    "    \n",
    "    # Remove original rows for both groups from the DataFrame\n",
    "    df_remaining = df[~df[unit_col].isin(group1_variants + group2_variants)]\n",
    "    \n",
    "    # Combine the remaining rows with the new aggregated rows\n",
    "    df_result = pd.concat([df_remaining, df_aggregated], ignore_index=True)\n",
    "    \n",
    "    # Sort by unit and date\n",
    "    df_result = df_result.sort_values(by=[unit_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Normalize the 'CENTRAL' column\n",
    "df_merged = normalize_central_column(df_merged)\n",
    "\n",
    "# 2. Format the 'FECHA' column to datetime\n",
    "df_merged = format_fecha_column(df_merged)\n",
    "\n",
    "# 3. Remove unwanted units\n",
    "df_merged = remove_unwanted_units(df_merged, unit_col=\"CENTRAL\")\n",
    "\n",
    "# 4. Fill missing dates by copying records from the same weekday one week later\n",
    "df_merged = fill_missing_with_next_available(df_merged, date_col='FECHA', central_col='CENTRAL')\n",
    "\n",
    "# 5. Standardize central names\n",
    "df_merged = standardize_central_names(df_merged, column=\"CENTRAL\")\n",
    "\n",
    "# 6. Remove daily duplicates by keeping the row with the highest hour sum\n",
    "df_merged = remove_daily_duplicates_by_max_hours(df_merged, date_col=\"FECHA\", unit_col=\"CENTRAL\")\n",
    "\n",
    "group_mapping = {\n",
    "    \"aes andres\": [\"aes andres fo\", \"aes andres gn\", \"aes andres\"],\n",
    "    \"cespm 1\": [\"cespm 1 fo\", \"cespm 1 gn\", \"cespm 1\"],\n",
    "    \"cespm 2\": [\"cespm 2 fo\", \"cespm 2 gn\", \"cespm 2\"],\n",
    "    \"cespm 3\": [\"cespm 3 fo\", \"cespm 3 gn\", \"cespm 3\"],\n",
    "    \"estrella del mar 2\": [\"estrella del mar 2 cfo\", \"estrella del mar 2 cgn\", \"estrella del mar 2 sfo\", \"estrella del mar 2 sgn\"],\n",
    "    \"estrella del mar 3\": [\"estrella del mar 3 ccp\", \"estrella del mar 3 cct\", \"estrella del mar 3 cs\", \"estrella del mar 3 sgn\", \"estrella del mar 3\"],\n",
    "    \"powership azua\": [\"powership azua kps 26\", \"powership azua kps 60\", \"powership azua\"],\n",
    "    \"los origenes\": [\"los origenes power plant fuel oil\", \"los origenes power plant gas natural\", \"los origenes\"],\n",
    "    \"quisqueya 1\": [\"quisqueya 1 fo\", \"quisqueya 1 gn\", \"quisqueya 1 san pedro\", \"quisqueya 1 san pedro fo\", \n",
    "                     \"quisqueya 1 san pedro gn\", \"quisqueya 1b san pedro\", \"quisqueya 1b san pedro fo\", \n",
    "                     \"quisqueya 1b san pedro gn\", \"quisqueya 1\"],\n",
    "    \"quisqueya 2\": [\"quisqueya 2 fo\", \"quisqueya 2 gn\"],\n",
    "    \"san felipe\": [\"san felipe cc\", \"san felipe vap\", \"san felipe\"]\n",
    "}\n",
    "# 7. aggregate \n",
    "df_merged = aggregate_unit_groups(df_merged, group_mapping, date_col=\"FECHA\", unit_col=\"CENTRAL\")\n",
    "df_merged = aggregate_los_mina(df_merged, date_col=\"FECHA\", unit_col=\"CENTRAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRUPOS</th>\n",
       "      <th>INDICE</th>\n",
       "      <th>GRUPO</th>\n",
       "      <th>EMPRESA</th>\n",
       "      <th>CENTRAL</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>H1</th>\n",
       "      <th>H2</th>\n",
       "      <th>H3</th>\n",
       "      <th>H4</th>\n",
       "      <th>...</th>\n",
       "      <th>H15</th>\n",
       "      <th>H16</th>\n",
       "      <th>H17</th>\n",
       "      <th>H18</th>\n",
       "      <th>H19</th>\n",
       "      <th>H20</th>\n",
       "      <th>H21</th>\n",
       "      <th>H22</th>\n",
       "      <th>H23</th>\n",
       "      <th>H24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aes andres</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>207.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>254.0</td>\n",
       "      <td>229.00</td>\n",
       "      <td>236.0</td>\n",
       "      <td>220.00</td>\n",
       "      <td>260.00</td>\n",
       "      <td>260.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aes andres</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>239.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>...</td>\n",
       "      <td>246.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>238.00</td>\n",
       "      <td>284.0</td>\n",
       "      <td>273.00</td>\n",
       "      <td>260.0</td>\n",
       "      <td>224.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>256.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aes andres</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>224.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>279.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>246.00</td>\n",
       "      <td>280.0</td>\n",
       "      <td>262.00</td>\n",
       "      <td>246.0</td>\n",
       "      <td>230.00</td>\n",
       "      <td>230.00</td>\n",
       "      <td>230.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aes andres</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>256.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>...</td>\n",
       "      <td>276.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>261.00</td>\n",
       "      <td>241.0</td>\n",
       "      <td>253.00</td>\n",
       "      <td>219.0</td>\n",
       "      <td>276.00</td>\n",
       "      <td>240.00</td>\n",
       "      <td>256.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aes andres</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423905</th>\n",
       "      <td>4 - Hidroeléctrica</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hidroeléctrica</td>\n",
       "      <td>EGEHID</td>\n",
       "      <td>valdesia 2</td>\n",
       "      <td>2025-03-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423906</th>\n",
       "      <td>4 - Hidroeléctrica</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hidroeléctrica</td>\n",
       "      <td>EGEHID</td>\n",
       "      <td>valdesia 2</td>\n",
       "      <td>2025-03-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423907</th>\n",
       "      <td>4 - Hidroeléctrica</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hidroeléctrica</td>\n",
       "      <td>EGEHID</td>\n",
       "      <td>valdesia 2</td>\n",
       "      <td>2025-03-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423908</th>\n",
       "      <td>4 - Hidroeléctrica</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hidroeléctrica</td>\n",
       "      <td>EGEHID</td>\n",
       "      <td>valdesia 2</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.31</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.99</td>\n",
       "      <td>21.09</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423909</th>\n",
       "      <td>4 - Hidroeléctrica</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hidroeléctrica</td>\n",
       "      <td>EGEHID</td>\n",
       "      <td>valdesia 2</td>\n",
       "      <td>2025-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>423910 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    GRUPOS  INDICE           GRUPO EMPRESA     CENTRAL  \\\n",
       "0                      NaN     NaN             NaN     NaN  aes andres   \n",
       "1                      NaN     NaN             NaN     NaN  aes andres   \n",
       "2                      NaN     NaN             NaN     NaN  aes andres   \n",
       "3                      NaN     NaN             NaN     NaN  aes andres   \n",
       "4                      NaN     NaN             NaN     NaN  aes andres   \n",
       "...                    ...     ...             ...     ...         ...   \n",
       "423905  4 - Hidroeléctrica     4.0  Hidroeléctrica  EGEHID  valdesia 2   \n",
       "423906  4 - Hidroeléctrica     4.0  Hidroeléctrica  EGEHID  valdesia 2   \n",
       "423907  4 - Hidroeléctrica     4.0  Hidroeléctrica  EGEHID  valdesia 2   \n",
       "423908  4 - Hidroeléctrica     4.0  Hidroeléctrica  EGEHID  valdesia 2   \n",
       "423909  4 - Hidroeléctrica     4.0  Hidroeléctrica  EGEHID  valdesia 2   \n",
       "\n",
       "            FECHA     H1     H2     H3     H4  ...    H15    H16    H17  \\\n",
       "0      2013-01-01  207.0  241.0  217.0  220.0  ...  237.0  265.0  234.0   \n",
       "1      2013-01-02  239.0  275.0  277.0  249.0  ...  246.0  250.0  248.0   \n",
       "2      2013-01-03  224.0  261.0  223.0  239.0  ...  279.0  276.0  231.0   \n",
       "3      2013-01-04  256.0  227.0  202.0  230.0  ...  276.0  273.0  266.0   \n",
       "4      2013-01-05    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0   \n",
       "...           ...    ...    ...    ...    ...  ...    ...    ...    ...   \n",
       "423905 2025-03-15    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0   \n",
       "423906 2025-03-16    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0   \n",
       "423907 2025-03-17    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0   \n",
       "423908 2025-03-18    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0   \n",
       "423909 2025-03-19    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0   \n",
       "\n",
       "           H18    H19     H20    H21     H22     H23     H24  \n",
       "0       220.00  254.0  229.00  236.0  220.00  260.00  260.00  \n",
       "1       238.00  284.0  273.00  260.0  224.00  210.00  256.00  \n",
       "2       246.00  280.0  262.00  246.0  230.00  230.00  230.00  \n",
       "3       261.00  241.0  253.00  219.0  276.00  240.00  256.00  \n",
       "4         0.00    0.0    0.00    0.0    0.00    0.00    0.00  \n",
       "...        ...    ...     ...    ...     ...     ...     ...  \n",
       "423905    0.00    0.0    0.00    0.0    0.00    0.00    0.00  \n",
       "423906    0.00    0.0    0.00    0.0    0.00    0.00    0.00  \n",
       "423907    0.00    0.0    0.00    0.0    0.00    0.00    0.00  \n",
       "423908    9.31   21.1   21.18   21.1   20.99   21.09    3.27  \n",
       "423909    0.00    0.0    0.00    0.0    0.00    0.00    0.00  \n",
       "\n",
       "[423910 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watch each Central Unit and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CENTRAL</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aes andres</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aguacate 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aguacate 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aniana vargas 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aniana vargas 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baiguaque 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baiguaque 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>barahona carbon</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cespm 3</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cespm 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cespm 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>disponibilidad real</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contra embalse moncion 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>contra embalse moncion 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>consumo</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>estrella del mar 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>haina tg</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>domingo rodriguez 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>el salto</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>disponibilidad real sinc.</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>domingo rodriguez 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>las barias</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>los anones</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>la vega</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jimenoa</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jiguey 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jiguey 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>itabo 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>itabo 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>inca km22</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hatillo 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>monte rio</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>los toros 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>los toros 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>magueyal 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>magueyal 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>metaldom</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>moncion 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>moncion 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>palomino 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nizao najayo</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>las damas</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>lopez angostura</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>los cocos 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>los cocos 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>los mina</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>los origenes</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>palamara</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>palomino 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>valdesia 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>total programado</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>total eolico</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>rio blanco 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rincon</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>reserva fria</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>sabaneta</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>total generado</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>total hidroelectrica</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pimentel 3</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>pimentel 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>pinalito 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pimentel 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>pinalito 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>san felipe</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>san lorenzo 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tavera 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>sultana del este</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tavera 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sabana yegua</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>reserva caliente</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>potencia no servida</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>rosa julia de la cruz</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>rio blanco 2</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>valdesia 1</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>total termico</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>quilvio cabrera</td>\n",
       "      <td>4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>quisqueya 2</td>\n",
       "      <td>4219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>quisqueya 1</td>\n",
       "      <td>4217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>san pedro vapor</td>\n",
       "      <td>3952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>bersal</td>\n",
       "      <td>3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>brazo derecho</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>cepp 2</td>\n",
       "      <td>3343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>cepp 1</td>\n",
       "      <td>3343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>parque eolico larimar</td>\n",
       "      <td>3238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>monte plata solar</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>san pedro bio-energy</td>\n",
       "      <td>2959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>palenque</td>\n",
       "      <td>2572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>rio san juan</td>\n",
       "      <td>2484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>parque fotovoltaico montecristi solar 1</td>\n",
       "      <td>2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>parque eolico larimar ii</td>\n",
       "      <td>2347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>punta catalina 1</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>parque eolico agua clara</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>parque eolico guanillo</td>\n",
       "      <td>2155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>punta catalina 2</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>total solar</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>hatillo 2</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>parque fotovoltaico mata de palma</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>parque eolico los guzmancitos</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>parque solar canoa</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>haina 4</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>parque fotovoltaico bayasol</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>parque eolico matafongo</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>parque solar girasol</td>\n",
       "      <td>1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>estrella del mar 3</td>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>haina 1</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>haina 2</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>parque fotovoltaico santanasol</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>parque solar el soco</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>parque eolico los guzmancitos 2</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>parque eolico de matafongo</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>siba</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>parque solar esperanza</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>estrella del mar</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>powership azua</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>parque fotovoltaico calabaza</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>parque fotovoltaico matrisol</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>parque fotovoltaico cumayasa 2</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>parque fotovoltaico cumayasa 1</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>parque fotovoltaico los negros</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>generacion de emergencia aes andres</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>pimentel 4</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>parque fotovoltaico maranatha fase i</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>parque fotovoltaico sajoma</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>parque fotovoltaico la victoria</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>parque fotovoltaico mirasol</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>parque fotovoltaico washington capital 3</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>parque fotovoltaico washington capital 2</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      CENTRAL  count\n",
       "0                                  aes andres   4461\n",
       "1                                  aguacate 1   4461\n",
       "2                                  aguacate 2   4461\n",
       "3                             aniana vargas 1   4461\n",
       "4                             aniana vargas 2   4461\n",
       "5                                 baiguaque 1   4461\n",
       "6                                 baiguaque 2   4461\n",
       "7                             barahona carbon   4461\n",
       "8                                     cespm 3   4461\n",
       "9                                     cespm 2   4461\n",
       "10                                    cespm 1   4461\n",
       "11                        disponibilidad real   4461\n",
       "12                   contra embalse moncion 2   4461\n",
       "13                   contra embalse moncion 1   4461\n",
       "14                                    consumo   4461\n",
       "15                         estrella del mar 2   4461\n",
       "16                                   haina tg   4461\n",
       "17                        domingo rodriguez 2   4461\n",
       "18                                   el salto   4461\n",
       "19                  disponibilidad real sinc.   4461\n",
       "20                        domingo rodriguez 1   4461\n",
       "21                                 las barias   4461\n",
       "22                                 los anones   4461\n",
       "23                                    la vega   4461\n",
       "24                                    jimenoa   4461\n",
       "25                                   jiguey 1   4461\n",
       "26                                   jiguey 2   4461\n",
       "27                                    itabo 2   4461\n",
       "28                                    itabo 1   4461\n",
       "29                                  inca km22   4461\n",
       "30                                  hatillo 1   4461\n",
       "31                                  monte rio   4461\n",
       "32                                los toros 1   4461\n",
       "33                                los toros 2   4461\n",
       "34                                 magueyal 1   4461\n",
       "35                                 magueyal 2   4461\n",
       "36                                   metaldom   4461\n",
       "37                                  moncion 1   4461\n",
       "38                                  moncion 2   4461\n",
       "39                                 palomino 2   4461\n",
       "40                               nizao najayo   4461\n",
       "41                                  las damas   4461\n",
       "42                            lopez angostura   4461\n",
       "43                                los cocos 2   4461\n",
       "44                                los cocos 1   4461\n",
       "45                                   los mina   4461\n",
       "46                               los origenes   4461\n",
       "47                                   palamara   4461\n",
       "48                                 palomino 1   4461\n",
       "49                                 valdesia 2   4461\n",
       "50                           total programado   4461\n",
       "51                               total eolico   4461\n",
       "52                               rio blanco 1   4461\n",
       "53                                     rincon   4461\n",
       "54                               reserva fria   4461\n",
       "55                                   sabaneta   4461\n",
       "56                             total generado   4461\n",
       "57                       total hidroelectrica   4461\n",
       "58                                 pimentel 3   4461\n",
       "59                                 pimentel 2   4461\n",
       "60                                 pinalito 1   4461\n",
       "61                                 pimentel 1   4461\n",
       "62                                 pinalito 2   4461\n",
       "63                                 san felipe   4461\n",
       "64                              san lorenzo 1   4461\n",
       "65                                   tavera 1   4461\n",
       "66                           sultana del este   4461\n",
       "67                                   tavera 2   4461\n",
       "68                               sabana yegua   4461\n",
       "69                           reserva caliente   4461\n",
       "70                        potencia no servida   4461\n",
       "71                      rosa julia de la cruz   4461\n",
       "72                               rio blanco 2   4461\n",
       "73                                 valdesia 1   4461\n",
       "74                              total termico   4461\n",
       "75                            quilvio cabrera   4380\n",
       "76                                quisqueya 2   4219\n",
       "77                                quisqueya 1   4217\n",
       "78                            san pedro vapor   3952\n",
       "79                                     bersal   3862\n",
       "80                              brazo derecho   3849\n",
       "81                                     cepp 2   3343\n",
       "82                                     cepp 1   3343\n",
       "83                      parque eolico larimar   3238\n",
       "84                          monte plata solar   3194\n",
       "85                       san pedro bio-energy   2959\n",
       "86                                   palenque   2572\n",
       "87                               rio san juan   2484\n",
       "88    parque fotovoltaico montecristi solar 1   2396\n",
       "89                   parque eolico larimar ii   2347\n",
       "90                           punta catalina 1   2232\n",
       "91                   parque eolico agua clara   2218\n",
       "92                     parque eolico guanillo   2155\n",
       "93                           punta catalina 2   2030\n",
       "94                                total solar   2012\n",
       "95                                  hatillo 2   1996\n",
       "96          parque fotovoltaico mata de palma   1943\n",
       "97              parque eolico los guzmancitos   1943\n",
       "98                         parque solar canoa   1943\n",
       "99                                    haina 4   1555\n",
       "100               parque fotovoltaico bayasol   1469\n",
       "101                   parque eolico matafongo   1360\n",
       "102                      parque solar girasol   1350\n",
       "103                        estrella del mar 3   1274\n",
       "104                                   haina 1   1269\n",
       "105                                   haina 2   1203\n",
       "106            parque fotovoltaico santanasol   1028\n",
       "107                      parque solar el soco    986\n",
       "108           parque eolico los guzmancitos 2    867\n",
       "109                parque eolico de matafongo    796\n",
       "110                                      siba    762\n",
       "111                    parque solar esperanza    703\n",
       "112                          estrella del mar    700\n",
       "113                            powership azua    675\n",
       "114              parque fotovoltaico calabaza    664\n",
       "115              parque fotovoltaico matrisol    602\n",
       "116            parque fotovoltaico cumayasa 2    562\n",
       "117            parque fotovoltaico cumayasa 1    562\n",
       "118            parque fotovoltaico los negros    519\n",
       "119       generacion de emergencia aes andres    434\n",
       "120                                pimentel 4    302\n",
       "121      parque fotovoltaico maranatha fase i    276\n",
       "122                parque fotovoltaico sajoma    219\n",
       "123           parque fotovoltaico la victoria    118\n",
       "124               parque fotovoltaico mirasol    111\n",
       "125  parque fotovoltaico washington capital 3     71\n",
       "126  parque fotovoltaico washington capital 2     71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configurar para que se muestren todas las filas\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Contar las ocurrencias de cada valor en la columna 'CENTRAL'\n",
    "central_counts = df_merged['CENTRAL'].value_counts().reset_index()\n",
    "central_counts.columns = ['CENTRAL', 'count']\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "display(central_counts)\n",
    "\n",
    "# (Opcional) Restaurar la configuración predeterminada si es necesario\n",
    "pd.reset_option('display.max_rows')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
